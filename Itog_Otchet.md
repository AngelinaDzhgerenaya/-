**1. Введение**
   
Проект был посвящен разработке модели машинного обучения для автоматической классификации жанров фильмов на основе их текстовых описаний. Цель состояла в создании точной и эффективной модели, устойчивой к переобучению и способной обрабатывать разнообразные текстовые данные. Отчёт описывает этапы проекта, включая подготовку данных, построение и оптимизацию модели, а также анализ полученных результатов.

**2. Подготовка данных**

Этот этап включал следующие шаги:

2.1 Токенизация: Текстовые описания фильмов были токенизированы с использованием библиотеки nltk. Процесс включал:<br />
 ᅠ ᅠ  ● Разбиение текста на слова (nltk.word_tokenize).<br />
  ᅠ ᅠ ● Приведение слов к нижнему регистру.<br />
  ᅠ ᅠ ● Удаление знаков препинания (string.punctuation).<br />
  ᅠ ᅠ ● Удаление стоп-слов (nltk.corpus.stopwords).<br />
2.2 Создание частотного словаря: Был создан словарь, сопоставляющий каждое уникальное слово в обучающем наборе данных с числовым индексом. Словарь был отсортирован по частоте встречаемости слов, наиболее частотные слова получили приоритетные индексы. В словарь были добавлены специальные токены <PAD>, <START> и <UNKNOWN> для обработки пустых последовательностей, начала последовательностей и неизвестных слов соответственно. В результате был создан словарь, содержащий более 10 000 уникальных слов.

**3. Построение и обучение модели**

3.1 Выбор архитектуры: В качестве базовой модели была выбрана рекуррентная нейронная сеть LSTM (Long Short-Term Memory), способная учитывать последовательные зависимости в тексте. Базовая архитектура включала:<br />
  ᅠ ᅠ ● Входной слой Embedding: Преобразует числовые индексы слов в плотные векторные представления (размерность 128).<br />
  ᅠ ᅠ ● Слой LSTM: Извлекает временные зависимости из последовательностей слов (размерность 64).<br />
  ᅠ ᅠ ● Выходной слой Dense: Производит классификацию жанров фильмов с использованием функции активации softmax.<br />
  ᅠ ᅠ ● Оптимизатор: Adam.<br />
  ᅠ ᅠ ● Функция потерь: categorical_crossentropy.<br />
3.2 Обучение базовой модели: Базовая модель показала точность на валидационной выборке около 76%.<br />
3.3 Улучшение модели: Для повышения точности были применены следующие методы:<br />
ᅠ ᅠ  ●3.3.1 Двунаправленный LSTM (Bi-LSTM): Добавление слоя Bidirectional(LSTM) позволило учитывать как предшествующий, так и последующий контекст слов, улучшив понимание смысла текста.<br />
ᅠ ᅠ  ●3.3.2 Регуляризация (Dropout): Добавление слоя Dropout с вероятностью отключения 0.5 помогло предотвратить переобучение модели.<br />
ᅠ ᅠ  ●3.3.3 Увеличение данных (Аугментация): Использовалась аугментация данных с помощью GPT-моделей для генерации синонимов, перефразирований и новых описаний фильмов. Это позволило увеличить объем обучающих данных и улучшить представление редких жанров.<br />
ᅠ ᅠ  ●3.3.4 Оптимизация обучения:<br />
  ᅠ ᅠ ᅠ ᅠ  ●Оптимизатор AdamW: Использование оптимизатора AdamW с весовой регуляризацией обеспечило более стабильное обучение.<br />
  ᅠ ᅠ ᅠ ᅠ  ●Динамическое изменение скорости обучения: Скорость обучения уменьшалась в процессе обучения по заданному расписанию, что позволило достичь более высокой точности.<br />

**4. Результаты**
   
Финальная модель, включающая все внесенные улучшения, показала следующие результаты:

  ᅠ ᅠ ● Точность на валидационной выборке: 84%<br />
  ᅠ ᅠ ● Точность на тестовой выборке: 86%<br />

Значительное улучшение точности по сравнению с базовой моделью свидетельствует об эффективности примененных методов. Кроме того, было отмечено улучшение классификации редких жанров за счёт увеличения данных и регуляризации.

**5. Заключение**
   
В ходе проекта была успешно разработана модель классификации жанров фильмов на основе текстового описания, достигшая высокой точности (86% на тестовой выборке). Были реализованы эффективные методы предобработки данных, построения и оптимизации модели LSTM с использованием Bi-LSTM, Dropout, AdamW и аугментации данных. Дальнейшие исследования могут включать использование механизмов внимания (Attention) или более сложных архитектур, таких как Transformers, для потенциального повышения точности и обработки более сложных текстовых структур.
